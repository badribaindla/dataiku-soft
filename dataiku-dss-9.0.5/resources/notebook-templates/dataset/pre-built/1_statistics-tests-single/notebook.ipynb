{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical analysis (Single Population) on __INPUT_DATASET_SMART_NAME__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Univariate analysis is perhaps the simplest form of statistical analysis. The key fact is that only one variable is involved.\n",
    "\n",
    "Bivariate analysis involves the analysis of two variables (often denoted as X, Y), for the purpose of determining the empirical relationship between them.\n",
    "\n",
    "<center>**For bivariate analysis please use the Statistical analysis (Multiple Populations) variant of this notebook.**</center>\n",
    "\n",
    "* [Setup and loading the data](#setup)\n",
    "* [Preprocessing of the data](#preprocessing)\n",
    "* [Statistical analysis and vizualisation](#general)\n",
    "* [Single population tests](#tests_single)\n",
    "\n",
    "<center><strong>Select Cell > Run All to execute the whole analysis</strong></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and dataset loading <a id=\"setup\" /> \n",
    "\n",
    "First of all, let's load the libraries that we'll use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dataiku                               # Access to Dataiku datasets\n",
    "import pandas as pd, numpy as np             # Data manipulation \n",
    "from matplotlib import pyplot as plt         # Graphing\n",
    "import seaborn as sns                        # Graphing\n",
    "#sns.set(style=\"white\")                       # Tuning the style of charts\n",
    "import warnings                              # Disable some warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "from scipy import stats                      # Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we do is now to load the dataset and put aside the three main types of columns:\n",
    "\n",
    "* Numerics\n",
    "* Categorical\n",
    "* Dates\n",
    "\n",
    "Statistical analysis requires having the data in memory, we are only going to load a sample of the data. Modify the following cell to change the size of the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_limit = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a DSS dataset as a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take a handle on the dataset\n",
    "mydataset = dataiku.Dataset(\"__INPUT_DATASET_SMART_NAME__\")\n",
    "\n",
    "# Load the first lines.\n",
    "# You can also load random samples, limit yourself to some columns, or only load\n",
    "# data matching some filters.\n",
    "#\n",
    "# Please refer to the Dataiku Python API documentation for more information\n",
    "df = mydataset.get_dataframe(limit = dataset_limit)\n",
    "\n",
    "df_orig = df.copy()\n",
    "\n",
    "# Get the column names\n",
    "numerical_columns = list(df.select_dtypes(include=[np.number]).columns)\n",
    "categorical_columns = list(df.select_dtypes(include=[object]).columns)\n",
    "date_columns = list(df.select_dtypes(include=['<M8[ns]']).columns)\n",
    "\n",
    "# Print a quick summary of what we just loaded\n",
    "print \"Loaded dataset\"\n",
    "print \"   Rows: %s\" % df.shape[0]\n",
    "print \"   Columns: %s (%s num, %s cat, %s date)\" % (df.shape[1], \n",
    "                                                    len(numerical_columns), len(categorical_columns),\n",
    "                                                    len(date_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of the data <a id=\"preprocessing\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will assume that the values are in the first numerical column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "value_col = numerical_columns[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the following lines to take control on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#value_col = u'my_value_column'\n",
    "print \"Selected value column is '%s'\" % (value_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We impute missing values in the value column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use mean for numerical features\n",
    "v = df[value_col].mean()\n",
    "if np.isnan(v):\n",
    "    v = 0\n",
    "print \"Filling value column '%s' with %s\" % (value_col, v)\n",
    "df[value_col] = df[value_col].fillna(v)\n",
    "df_pop_1 = df[value_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical analysis and vizualisation <a id=\"general\" /a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General statistics\n",
    "Number of records, mean, standard deviation, minimal value, quartiles, maximum value, mode, variance, skewness and kurtosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "additional_stats = [\"var\", \"skew\", \"kurtosis\"]\n",
    "print \"Stats about your series:\\n\", df_pop_1.describe().append(pd.Series(NaN if df_pop_1.mode().empty else df_pop_1.mode()[0], index=[\"mode\"])).append(pd.Series([df_pop_1.__getattr__(x)() for x in additional_stats], index=additional_stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram\n",
    "Histograms let you see the number of occurrences in your value column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title(\"Histogram of \"+value_col);\n",
    "plt.hist(df_pop_1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distplot\n",
    "Distplots combine an histogram with a kernel density estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(df_pop_1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple way of representing statistical data on a plot in which a rectangle is drawn to represent the second and third quartiles, with a vertical line inside to indicate the median value. The lower and upper quartiles are shown as horizontal lines either side of the rectangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.boxplot(df_pop_1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Violin plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The violin plot is similar to box plots, except that they also show the probability density of the data at different values. Violin plots include a marker for the median of the data and a box indicating the interquartile range, as in standard box plots. Overlaid on this box plot is a kernel density estimation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.violinplot(df_pop_1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Letter value plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letter value plots are an improvement upon boxplots for large datasets.\n",
    "\n",
    "They display the median and the quartiles, like a standard box plot, but will also draw boxes for subsequent \"eights\", \"sixteenth\" etc... which are generically called letter values.\n",
    "\n",
    "A cut off condition will leave a reasonable number of outliers out of the final boxes, helping you spot them easily.\n",
    "\n",
    "Letter value plots give a good sense of the distribution of data, and of its skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.lvplot(df_pop_1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical testing <a id=\"tests\" /a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reminder:** For a given significance level (e.g. 0.05), if the resulting p-value is smaller (p < 0.05), the null hypothesis is rejected. Otherwise (p â‰¥ 0.05) it cannot be rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define your confidence threshold here, default is 0.05\n",
    "confidence = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyse_results(confidence, pvalue, message, population_name=\"your series\"):\n",
    "    if pvalue < confidence:\n",
    "        print \"The hypothesis of \" + message + \" for \"+ population_name + \" is rejected with pvalue %s (smaller than %s)\" % (pvalue, confidence)\n",
    "    else:\n",
    "        print \"The hypothesis of \" + message + \" for \"+ population_name + \" can not be rejected, pvalue was %s (greater than %s)\" % (pvalue, confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single population tests <a id=\"tests_single\" /a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goodness of fit with a normal law: Shapiro-Wilk test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null-hypothesis of this test is that the population is normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pvalue_1 = stats.shapiro(df_pop_1)[1]\n",
    "test = 'normal distribution'\n",
    "analyse_results(confidence, pvalue_1, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for the average value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null-hypothesis of this test is that the population has the specified mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the mean you ant to test for here\n",
    "tested_mean = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pvalue_1 = stats.ttest_1samp(df_pop_1, tested_mean).pvalue\n",
    "test = 'mean=%s' % (tested_mean)\n",
    "analyse_results(confidence, pvalue_1, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>**If you have multiple populations and want to run bivariate analyses please use the Statistical analysis (Multiple Populations) variant of this notebook.**</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
